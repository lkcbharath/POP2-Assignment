\documentclass[12pt,a4paper]{report}

\usepackage{fullpage}
\usepackage{sectsty}
%\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{tabularx}
\usepackage{textcomp}
\usepackage{enumitem}

\usepackage{titlesec}
\titleformat{\chapter}[display]   
{\centering\normalfont\LARGE\bfseries}{\chaptertitlename\ \thechapter}{10pt}{\huge}
\titlespacing*{\chapter}{0pt}{-40pt}{20pt}


\setlength{\parindent}{2em}
%\setlength{\parskip}{0.5em}
\renewcommand{\baselinestretch}{1.5}
\newcommand\tab{\hspace{8mm}} 

\newenvironment{rcenter}
 {\setlength{\topsep}{1em}\center}
{\endcenter}




\begin{document}

\pagenumbering{roman}

\newpage
\chapter*{Title Page}

\newpage
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
"\underline{CoderStat}" 100-200words which should include the following:
> why the report has been written (i.e. what question or problem it is addressing?)
> how the study was undertaken
> what the main findings were
> what the significance of the findings is

\newpage

\tableofcontents

\pagenumbering{arabic}

\newpage
\chapter{Introduction}

Web Scraping is one of the most interesting fields in scripting. It involves retrieving useful information from the HTML code of a website.
JSON files are essentially databases structured in the form of a tree, with every key in the JSON tree attached to either a value or another JSON sub-tree.
Using this as an advantage, the focus of the system is to display statistics of multiple profiles attached to one or more user handles, on Competitive Programming Websites like HackerRank and CodeChef either by Web Scraping or by parsing a JSON object returned by the website containing the statistics itself.

\section{Web Scraping}
Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the HyperText Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.

Web scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page (which a browser does when you view the page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, then extraction can take place. The content of a page may be parsed, searched, reformatted, its data copied into a spreadsheet, and so on. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be to find and copy names and phone numbers, or companies and their URLs, to a list (contact scraping).

\section{JSON}
In computing, JavaScript Object Notation (JSON) is an open-standard file format that uses human-readable text to transmit data objects consisting of attribute–value pairs and array data types (or any other serializable value). It is a very common data format used for asynchronous browser–server communication, including as a replacement for XML in some AJAX-style systems.

JSON is a language-independent data format. It was derived from JavaScript, but as of 2017 many programming languages include code to generate and parse JSON-format data. 

\section{What is Competitive Programming?}
Competitive programming is a mind sport usually held over the Internet or a local network, involving participants trying to program according to provided specifications. Participants are referred to as competitive programmers. Competitive programming is recognized and supported by several multinational software and Internet companies, such as Google and Facebook. There are several organizations who host programming competitions on a regular basis.

\subsection{Rules}
A programming competition, sometimes referred to as a contest, generally involves the host presenting a set of logical or mathematical problems to the contestants, who are required to write computer programs capable of solving each problem. Judging is based mostly upon number of problems solved and time spent for writing successful solutions, but may also include other factors, like quality of output produced, execution time, program size, etc.

\subsection{Goals}
Typical problems belong to one of the following categories: combinatorics, number theory, graph theory, geometry, string analysis and data structures. Irrespective of the problem category, the process of solving a problem can be divided into two broad steps: constructing an efficient algorithm, and implementing the algorithm in a suitable programming language. These are the two most commonly tested skills in programming competitions.

\section{Problem Definition}
A user’s interest in Competitive programming is normally derived from watching a friend or colleague of the user participate in a contest, and starts to appreciate the task and wishes to do it himself/herself. The user may want to know more about other Competitive Programmers to be able to compete with them, as competition drives people more than anything else. 

Generally, the user may use a search engine to search for a handle, and results will show different statistics on different Competitive Programming Host websites. Since the statistics are different for each, it would be a convenience if the user could have a single page displaying the combined statistics of the said handle from different host websites. Thus, the system should be able to successfully display the aformentioned statistics.

\section{Objective of the Project}
\begin{itemize}[itemsep=0em]
	\item To obtain Competitive Programming statistics of a user
	\item Connect to and perform Web Scraping on different websites of the same.
	\item Categorize data by website
	\item Format data to ensure readability
	\item Display the formatted data to the user
\end{itemize}
\section{Challenges of the Project}
\begin{itemize}[itemsep=0em]
	\item Huge amount of data
	\item Procure relevant information from many lines of HTML or JSON files
	\item User profile may not exist
\end{itemize}

\newpage
\chapter{Literature Survey}
Many websites already exist as attempts to display a combined list of statistics for a user indulging in Competitive Programming by connecting to different websites and employing techniques like Web Scraping and API's. Upon analysis and a survey conducted within the campus, the majority have appreciated the value of a tool which runs right on the terminal without the need for an external agent like a browser.

\section{Related Work}
Proficiency in the course of Unix Programming and Practices is essential for building a robust system. The course featured tools like awk, cURL and sED, in addition to bash. Many other practices like correctness of syntax, clear code commends and performance improvements are used extensively in the system. The aformentioned websites were researched upon thoroughly to determine the method of sending requests for data retrieval and parsing.

\newpage
\chapter{System Architecture}
The basic steps involved in Web Scraping are finding the URL, identifying the site's HTML structure, using a tool to fetch the HTML content, then scraping the code itself, and finally isolating the results.

The basic steps involved in JSON parsing are fetching the JSON object, then using a JSON object parser tool to isolate results.

\section{Data collection}
Data collection is done from the user input on the command-line terminal. One or more handles are requested and stored in the system for further processing.
\section{Data preprocessing}
The system connects to the list of websites one-by-one and either 
\begin{itemize}[itemsep=0em]
	\item attempts to perform Web Scraping on them to retrieve the data as a HTML file, or
	\item downloads the JSON file upon sending a request to the website's API
\end{itemize}
\section{Data extraction}
The system then extracts relevant data from the files by
\begin{itemize}[itemsep=0em]
	\item using in-line text formatting tools to target specific lines
	\item remove spaces and unnecessary characters
\end{itemize}
\section{Classification and evaluation}
The data is classified by website and the functions are classified as such. Before data extraction, the files are checked for validity of user profile, usually by an indicator within them that shows whether the profile exists or not.

The statistics extracted from the data on a valid profile is assumed to be valid and is taken as it is. It is displayed to the user along with some meaningful text describing each of them.

\newpage
\chapter{Requirements and Specifications}

\section{Introduction}
Software requirement specification (SRS) is documentation, which is done once the requirements are collected from stakeholders. The requirements provided by the client are written in natural language. It is the duty of the system analyst to do the documentation of the requirements provided in technical language and pass this document to software development team. SRS shows how the developing software will interact with the interfaces, system response time, operational speed, security, portability and others.

\section{System Requirements}
The system needs both Hardware and Software equipment.

\subsection{Hardware Requirements}
Computing Requirements
\begin{itemize}[itemsep=0em]
	\item Processor: 1 GHz and above
	\item Main Memory: 5 MB
	\item Storage Space: Minimum of 5 MB
	\item Network: Internet Connection of 512 Kbps or above
\end{itemize}
\subsection{Software Requirements}
Development OS: Linux
For building the software, the requirements are:
\begin{itemize}[itemsep=0em]
	\item Text Editor (Sublime Text 3 used)
	\item bash
	\item cURL
	\item awk
	\item sED
	\item Python3
\end{itemize}

\section{Requirement Specification}
\subsection{Functional Requirements}
\begin{itemize}[itemsep=0em]
	\item The system must be able to input, output and process data.
	\item The system must not be interrupted during processing.
	\item The user should be familiar with text input, the handles and statistical analysis.
\end{itemize}
\subsection{Non-Functional Requirements}
\begin{itemize}[itemsep=0em]
	\item Availability: The system retrieves the most recent data stored.
	\item Reliability: The system must always function when required.
	\item Performance: The system should be able to process the data as fast as possible.
	\item Manageability: The system should be coded with proper documentation and formatting for readability.
	\item Flexibility: The system must be able to work in any environment and support adding of modules.
\end{itemize}

\newpage
\chapter{System Design}
\section{Data Flow Diagram}
The data flow diagram (DFD) shows the flow of data through several processes. DFD shows the preliminary overview steps of the proposed system. The DFD of the system is shown in Figure 5.1.

%\begin{center}
%   \includegraphics{./Resources/Data_Flow_Diagram.png}
%  \captionof{figure}{Data Flow Diagram of the system}
%\end{center}

\newpage
\section{Flowchart}
A flow chart diagram shows the flow of control step by step. Flow chart is useful in analyzing and designing of the system as shown in Figure 5.2.  

%\begin{center}
%   \includegraphics[scale=0.38]{./Resources/Flowchart.png}
%   \captionof{figure}{Flowchart showing each step}
%\end{center}

\newpage
\section{Use Case Diagram}
The use case diagram is used to represent the user interface between the systems, which indicates how the user interacts with the system. Figure 5.3 shows the different actors and interface with the application.

%\begin{center}
%   \includegraphics[scale=0.8]{./Resources/Use_Case_Diagram.png}
%   \captionof{figure}{Use Case Diagram detailing each use case}
%\end{center}

\newpage
\section{Sequence Diagram}
The sequence diagram indicates how and in what order the system operates. The sequence diagram of the system is as shown below, Figure 5.4 explains how the system communicates with each website. 

%\begin{center}
%   \includegraphics{./Resources/Sequence_Diagram.png}
%   \captionof{figure}{Sequence Diagram}
%\end{center}



\newpage
\chapter{System Implementation}
\section{Introduction}
This section describes the different system setup and modules that are used in implementing the system. The system uses the bash (Bourne Again SHell) scrpiting language as well as the Python3 programming language for implementation and user input data as the source data. 
\section{System Setup}
The system needs to have Ubuntu 18.04 or any other Linux distribution installed, along with Python3 version 3.6 or higher.

\section{Modules Description}
There are two modules used in the system, one of which is reused several times. The modules are explained briefly below:
\newpage
\subsection{Module 1: Fetch Data (Main Module)}
In the Main Module, we accept user data in the form of strings, which are checked for validity before passing them to other modules.

\begin{rcenter}
\begin{tabularx}{\textwidth}{ | X | } 
\hline
\textbf{Psuedo Code:} Fetch Data \\ 
\hline
string website{[6]}, choice \\
input website{[0]} \\

\tab \textbf{if} website[0] is null \textbf{do} \\
\tab\tab print "Error" \\
\tab\tab	return \\

input choice\\
\tab \textbf{if} string2 is 1 \textbf{do} \\
\tab\tab		\textbf{for} i = 0 to 5 \textbf{do} \\
\tab\tab		read website[i] \\
\tab\tab		\textbf{if} website[i] is null \textbf{do} \\
\tab\tab\tab		print "Error" \\
\tab\tab\tab		return \\
\tab\tab	else \\
\tab\tab\tab	\textbf{for} i = 0 to 5 \textbf{do} \\
\tab\tab\tab website[i] = website[0] \\

stopstalk() \\
spoj() \\
codeforces() \\
codechef() \\
return \\
\hline
\end{tabularx}
\end{rcenter}

\newpage
\subsection{Module 2: Retrieve and parse website data}
In this module, we retrieve the corresponding profile to the user input in the form of a HTML or JSON file, and filter it to produce relevant data. If no profile exists, print "No profile found".

\begin{rcenter}
\begin{tabularx}{\textwidth}{ | X | } 
\hline
\textbf{Psuedo Code:} Retrieve and parse data\\ 
\hline
string handle \\
\tab \textbf{for} each website \textbf{do} \\
\tab profile = curl(website) \\
\tab\tab \textbf{if} profile is not null \textbf{do} \\
\tab\tab\tab parse profile \\
\tab\tab\tab print statistics \\
\tab\tab else \\
\tab\tab\tab print "profile not valid" \\
return \\
\hline
\end{tabularx}
\end{rcenter}

\newpage
\chapter{System Testing}
\section{Introduction}
System testing checks whether the goal of the project has been successively achieved. System testing is done to check whether the system provides the accurate results. In development phase there are many modules created and each module must be tested, to check whether the module built provides the accurate result. Once the system is completed the integration test has to be conducted. It assures the software quality. There are different types of testing:

\textbf{Unit testing} – Each and every module will be tested separately to ensure the module works correctly for all possible instances.

\textbf{Integration testing} – The modules created are integrated together and the integrated system is been checked to ensure that the system works perfectly even after integrating.   

\textbf{System testing} – The system after integrating every integration and sub-integration, the entire system will be tested. The entire system will be tested which includes function, acceptance, installation and regression testing.

\newpage
\section{Test Cases}

During the development phase some of the additional changes are added to the system. So each phase tested accordingly to the integrated system. Each test case has been explained below.  

\begin{center}
\begin{tabularx}{\textwidth} { | X | X | X | X | } 
 \hline
Test ID & Test Description & Expected Result & Obtained Result \\ 
\hline
1 & Empty Input & No profile found & No profile found \\ 
\hline 
2 & Handle with no valid profile & No profile found & No profile found \\ 
\hline
3 & Handle with valid profile & Profile found & Profile found \\ 
\hline
\end{tabularx}
\captionof{table}{Test cases of system}
\end{center}


\newpage
\chapter{Results and Discussion}
The software is run on a software Terminal on a Linux-based Operating System. Upon entering a valid handle, the output is as shown on figure 9.1.

%\begin{center}
%   \includegraphics[scale=0.75]{./Resources/Output.png}
%   \captionof{figure}{Snapshot of the statistics of a user}
%\end{center}

\newpage
\chapter{Conclusion and Future Work}
\section{Conclusion}
After repeated testing and reiterating the design of the system, it has successfully been able to realise its objective, which is to display the Competitive Programming statistics of a given user handle, in a readable format.

\section{Future work}
\begin{itemize}[itemsep=0em]
	\item Support for websites like HackerRank \& HackerEarth once their public API's are released
	\item Add support for websites like TopCoder once they are relevant in the field of Competitive Programming
	\item In the future, using JavaScript, add more functionality for displaying statistics
\end{itemize}

\newpage
\chapter{References}
\begin{itemize}[itemsep=0em]
	\item www.codechef.com
	\item www.spoj.com
	\item www.codeforces.com/api
	\item www.stopstalk.com
\end{itemize}

\end{document}